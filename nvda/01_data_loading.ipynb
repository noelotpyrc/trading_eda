{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. NVDA OHLC Data Loading & Initial Processing\n",
        "\n",
        "This notebook loads all OHLC CSV files from the `data/` folder into a single DataFrame and performs initial data processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available CSV files:\n",
            "Found 1107 CSV files\n",
            "data/20210104_ohlc_NVDA.csv\n",
            "data/20210105_ohlc_NVDA.csv\n",
            "data/20210106_ohlc_NVDA.csv\n",
            "data/20210107_ohlc_NVDA.csv\n",
            "data/20210108_ohlc_NVDA.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Available CSV files:\")\n",
        "# Path to data folder\n",
        "data_path = 'data'\n",
        "\n",
        "# Find all relevant CSV files\n",
        "csv_files = glob.glob(os.path.join(data_path, '*_ohlc_NVDA.csv'))\n",
        "print(f\"Found {len(csv_files)} CSV files\")\n",
        "\n",
        "# Sort files by date to ensure consistent ordering\n",
        "csv_files.sort()\n",
        "\n",
        "for file in csv_files[:5]:  # Show first 5 files\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1107 files\n",
            "Combined DataFrame shape: (865782, 12)\n",
            "Date range: 2021-01-04 to 2025-05-30\n",
            "Columns: ['time', 'timestamp', 'open', 'high', 'low', 'close', 'vwap', 'volume', 'transactions', 'otc', 'date', 'date_str']\n"
          ]
        }
      ],
      "source": [
        "# Load and combine all CSV files\n",
        "dfs = []\n",
        "\n",
        "for file in csv_files:\n",
        "    # Extract date from filename (first 8 digits: YYYYMMDD)\n",
        "    basename = os.path.basename(file)\n",
        "    date_str = basename.split('_')[0]  # e.g., '20250529' from '20250529_ohlc_NVDA.csv'\n",
        "    \n",
        "    # Convert to proper date format\n",
        "    date_obj = datetime.strptime(date_str, '%Y%m%d').date()\n",
        "    \n",
        "    # Read CSV\n",
        "    df = pd.read_csv(file)\n",
        "    \n",
        "    # Add date column\n",
        "    df['date'] = date_obj\n",
        "    df['date_str'] = date_str\n",
        "    \n",
        "    dfs.append(df)\n",
        "    \n",
        "print(f\"Loaded {len(dfs)} files\")\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "all_data = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(f\"Combined DataFrame shape: {all_data.shape}\")\n",
        "print(f\"Date range: {all_data['date'].min()} to {all_data['date'].max()}\")\n",
        "print(f\"Columns: {list(all_data.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 rows:\n",
            "                time      timestamp     open     high      low    close  \\\n",
            "0  20210104 04:07:00  1609751220000  13.0800  13.0800  13.0700  13.0700   \n",
            "1  20210104 04:16:00  1609751760000  13.1200  13.1245  13.1200  13.1245   \n",
            "2  20210104 04:17:00  1609751820000  13.1223  13.1223  13.1223  13.1223   \n",
            "3  20210104 04:24:00  1609752240000  13.1250  13.1250  13.1250  13.1250   \n",
            "4  20210104 04:59:00  1609754340000  13.1568  13.1568  13.1568  13.1568   \n",
            "5  20210104 05:14:00  1609755240000  13.1500  13.1500  13.1500  13.1500   \n",
            "6  20210104 05:19:00  1609755540000  13.1380  13.1380  13.1380  13.1380   \n",
            "7  20210104 05:21:00  1609755660000  13.1380  13.1380  13.1380  13.1380   \n",
            "8  20210104 05:27:00  1609756020000  13.1375  13.1375  13.1375  13.1375   \n",
            "9  20210104 05:58:00  1609757880000  13.1375  13.1375  13.1375  13.1375   \n",
            "\n",
            "      vwap   volume  transactions  otc        date  date_str  \n",
            "0  13.0792  21840.0            11  NaN  2021-01-04  20210104  \n",
            "1  13.1130  45440.0            26  NaN  2021-01-04  20210104  \n",
            "2  13.1121   5440.0             2  NaN  2021-01-04  20210104  \n",
            "3  13.1250  12000.0             3  NaN  2021-01-04  20210104  \n",
            "4  13.1550  22840.0            16  NaN  2021-01-04  20210104  \n",
            "5  13.1493   8040.0             8  NaN  2021-01-04  20210104  \n",
            "6  13.1383   7560.0             7  NaN  2021-01-04  20210104  \n",
            "7  13.1378  20240.0             9  NaN  2021-01-04  20210104  \n",
            "8  13.1375  13840.0             8  NaN  2021-01-04  20210104  \n",
            "9  13.1375   9920.0             6  NaN  2021-01-04  20210104  \n",
            "\n",
            "Data types:\n",
            "time             object\n",
            "timestamp         int64\n",
            "open            float64\n",
            "high            float64\n",
            "low             float64\n",
            "close           float64\n",
            "vwap            float64\n",
            "volume          float64\n",
            "transactions      int64\n",
            "otc             float64\n",
            "date             object\n",
            "date_str         object\n",
            "dtype: object\n",
            "\n",
            "Sample of unique dates:\n",
            "[datetime.date(2021, 1, 4), datetime.date(2021, 1, 5), datetime.date(2021, 1, 6), datetime.date(2021, 1, 7), datetime.date(2021, 1, 8), datetime.date(2021, 1, 11), datetime.date(2021, 1, 12), datetime.date(2021, 1, 13), datetime.date(2021, 1, 14), datetime.date(2021, 1, 15)]\n"
          ]
        }
      ],
      "source": [
        "# Display sample data\n",
        "print(\"First 10 rows:\")\n",
        "print(all_data.head(10))\n",
        "\n",
        "print(\"\\nData types:\")\n",
        "print(all_data.dtypes)\n",
        "\n",
        "print(\"\\nSample of unique dates:\")\n",
        "print(sorted(all_data['date'].unique())[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Summary:\n",
            "Total records: 865,782\n",
            "Date range: 2021-01-04 to 2025-05-30\n",
            "Number of unique dates: 1107\n",
            "Average records per day: 782.1\n",
            "\n",
            "Missing values per column:\n",
            "time                 0\n",
            "timestamp            0\n",
            "open                 0\n",
            "high                 0\n",
            "low                  0\n",
            "close                0\n",
            "vwap                 0\n",
            "volume               0\n",
            "transactions         0\n",
            "otc             865782\n",
            "date                 0\n",
            "date_str             0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Data summary\n",
        "print(\"Data Summary:\")\n",
        "print(f\"Total records: {len(all_data):,}\")\n",
        "print(f\"Date range: {all_data['date'].min()} to {all_data['date'].max()}\")\n",
        "print(f\"Number of unique dates: {all_data['date'].nunique()}\")\n",
        "print(f\"Average records per day: {len(all_data) / all_data['date'].nunique():.1f}\")\n",
        "\n",
        "# Check for any missing data\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(all_data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "Let's ensure our data types are correct and check for duplicates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows: 0\n",
            "\n",
            "Updated data types:\n",
            "time                    object\n",
            "timestamp                int64\n",
            "open                   float64\n",
            "high                   float64\n",
            "low                    float64\n",
            "close                  float64\n",
            "vwap                   float64\n",
            "volume                 float64\n",
            "transactions             int64\n",
            "otc                    float64\n",
            "date            datetime64[ns]\n",
            "date_str                object\n",
            "datetime        datetime64[ns]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Convert date column to datetime type\n",
        "all_data['date'] = pd.to_datetime(all_data['date'])\n",
        "\n",
        "# Create a proper datetime column by combining date and time\n",
        "all_data['datetime'] = pd.to_datetime(all_data['date'].dt.strftime('%Y-%m-%d') + ' ' + all_data['time'].str.split(' ').str[1])\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicates = all_data.duplicated()\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
        "\n",
        "# Drop duplicates if any\n",
        "if duplicates.sum() > 0:\n",
        "    all_data = all_data.drop_duplicates()\n",
        "    print(f\"Dropped {duplicates.sum()} duplicate rows\")\n",
        "    print(f\"New DataFrame shape: {all_data.shape}\")\n",
        "\n",
        "# Display the updated data types\n",
        "print(\"\\nUpdated data types:\")\n",
        "print(all_data.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cleaned combined data saved to 'combined_nvda_ohlc_clean.csv'\n",
            "This file will be used as input for subsequent analysis notebooks.\n"
          ]
        }
      ],
      "source": [
        "# Save the cleaned combined dataset for use in other notebooks\n",
        "all_data.to_csv('combined_nvda_ohlc_clean.csv', index=False)\n",
        "print(\"\\nCleaned combined data saved to 'combined_nvda_ohlc_clean.csv'\")\n",
        "print(\"This file will be used as input for subsequent analysis notebooks.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
