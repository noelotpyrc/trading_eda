{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trader Clustering Model\n",
    "\n",
    "Build clustering model using:\n",
    "1. First day trading data: `trader_features` and `trader_coin_performance` \n",
    "2. First two hours trading data: `trader_coin_features`\n",
    "\n",
    "Goal: Identify trader patterns to predict behavior when new coins launch\n",
    "\n",
    "For this notebook: check the data quality and prepare the data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/noel/projects/trading_eda/solana')\n",
    "\n",
    "from solana_eda_utils import SolanaDataAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "# Connect to database\n",
    "con = duckdb.connect('/Volumes/Extreme SSD/DuckDB/solana.duckdb', read_only=True)\n",
    "print(\"Database connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Data Check - Available Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables:\n",
      "                                   name\n",
      "0                  coin_first_two_hours\n",
      "1                      first_day_trades\n",
      "2  trader_coin_first_two_hours_features\n",
      "3               trader_coin_performance\n",
      "4                       trader_features\n",
      "\n",
      "Table sizes:\n",
      "coin_first_two_hours: 133,394,160 rows\n",
      "first_day_trades: 325,171,663 rows\n",
      "trader_coin_first_two_hours_features: 17,585,219 rows\n",
      "trader_coin_performance: 43,441,089 rows\n",
      "trader_features: 10,060,972 rows\n"
     ]
    }
   ],
   "source": [
    "# Check available tables\n",
    "tables = con.execute('SHOW TABLES').fetchdf()\n",
    "print(\"Available tables:\")\n",
    "print(tables)\n",
    "\n",
    "# Check table sizes\n",
    "print(\"\\nTable sizes:\")\n",
    "for table in tables['name']:\n",
    "    count = con.execute(f'SELECT COUNT(*) as count FROM {table}').fetchdf()\n",
    "    print(f\"{table}: {count.iloc[0]['count']:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine First Day Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trader_features table structure:\n",
      "                         column_name column_type null   key default extra\n",
      "0                            swapper     VARCHAR  YES  None    None  None\n",
      "1                 total_trades_count      BIGINT  YES  None    None  None\n",
      "2                    total_sol_spent      DOUBLE  YES  None    None  None\n",
      "3                 total_sol_received      DOUBLE  YES  None    None  None\n",
      "4                 avg_sol_trade_size      DOUBLE  YES  None    None  None\n",
      "5              median_sol_trade_size      DOUBLE  YES  None    None  None\n",
      "6               max_single_sol_trade      DOUBLE  YES  None    None  None\n",
      "7                 min_sol_trade_size      DOUBLE  YES  None    None  None\n",
      "8             sol_trade_size_std_dev      DOUBLE  YES  None    None  None\n",
      "9   trade_size_coefficient_variation      DOUBLE  YES  None    None  None\n",
      "10                       net_sol_pnl      DOUBLE  YES  None    None  None\n",
      "11               unique_coins_traded      DOUBLE  YES  None    None  None\n",
      "12               avg_trades_per_coin       FLOAT  YES  None    None  None\n",
      "13         trade_concentration_ratio       FLOAT  YES  None    None  None\n",
      "14                 trading_span_days      DOUBLE  YES  None    None  None\n",
      "15                    trades_per_day      DOUBLE  YES  None    None  None\n",
      "16          avg_hours_between_trades      DOUBLE  YES  None    None  None\n",
      "17                      active_hours      BIGINT  YES  None    None  None\n",
      "18                       active_days      BIGINT  YES  None    None  None\n",
      "19            trades_per_active_hour       FLOAT  YES  None    None  None\n",
      "20           round_number_preference       FLOAT  YES  None    None  None\n",
      "21               sol_to_token_trades      BIGINT  YES  None    None  None\n",
      "22               token_to_sol_trades      BIGINT  YES  None    None  None\n",
      "23             token_to_token_trades      BIGINT  YES  None    None  None\n",
      "24        unique_from_tokens_non_sol      BIGINT  YES  None    None  None\n",
      "25          unique_to_tokens_non_sol      BIGINT  YES  None    None  None\n",
      "26           sol_to_token_percentage       FLOAT  YES  None    None  None\n",
      "27           token_to_sol_percentage       FLOAT  YES  None    None  None\n",
      "28         token_to_token_percentage       FLOAT  YES  None    None  None\n",
      "29                    buy_sell_ratio       FLOAT  YES  None    None  None\n",
      "\n",
      "trader_features sample:\n",
      "                                        swapper  total_trades_count  \\\n",
      "0   arsc4jbDnzaqcCLByyGo7fg7S2SmcFsWUzQuDtLZh2y              151632   \n",
      "1  HV1KXxWFaSeriyFvXyx48FqG9BoFbfinB8njCJonqP7K             1279901   \n",
      "2  8MqRTAQnjhDYH7TWS1b1DjFog4CLZfySWE5cZeotG2VW              105378   \n",
      "3  AD65fgYti96iSSzSPaNazV9Bs29m7JbNomGjG4Cp5WFS               68131   \n",
      "4  D4zVhwuUsFbcaty7wJhNEZ7VEwPHXQ5d2heXPxM5yWhL               74918   \n",
      "\n",
      "   total_sol_spent  total_sol_received  avg_sol_trade_size  \\\n",
      "0     3.165754e+06        3.209894e+06             41.7557   \n",
      "1     1.562690e+06        2.439516e+04              1.3016   \n",
      "2     1.221408e+06        1.237385e+06             23.2609   \n",
      "3     1.027367e+06        1.043267e+06             30.1528   \n",
      "4     8.597928e+05        8.579472e+05             22.5348   \n",
      "\n",
      "   median_sol_trade_size  max_single_sol_trade  min_sol_trade_size  \\\n",
      "0                15.4261             2970.0000              0.0001   \n",
      "1                 0.1759             2330.7915              0.0000   \n",
      "2                 9.4538             2024.6330              0.0001   \n",
      "3                10.3493             2970.0000              0.0000   \n",
      "4                 9.9653             1295.2484              0.0000   \n",
      "\n",
      "   sol_trade_size_std_dev  trade_size_coefficient_variation  ...  \\\n",
      "0                107.4546                            2.5734  ...   \n",
      "1                  7.5630                            5.8106  ...   \n",
      "2                 54.1730                            2.3289  ...   \n",
      "3                 96.0312                            3.1848  ...   \n",
      "4                 48.0948                            2.1342  ...   \n",
      "\n",
      "   round_number_preference  sol_to_token_trades  token_to_sol_trades  \\\n",
      "0                 0.000000                75816                75816   \n",
      "1                 0.001830              1200601                10386   \n",
      "2                 0.000000                52509                52869   \n",
      "3                 0.000000                34072                34059   \n",
      "4                 0.034885                38154                36747   \n",
      "\n",
      "   token_to_token_trades  unique_from_tokens_non_sol  \\\n",
      "0                      0                           0   \n",
      "1                  68914                          41   \n",
      "2                      0                           0   \n",
      "3                      0                           0   \n",
      "4                     17                           4   \n",
      "\n",
      "   unique_to_tokens_non_sol  sol_to_token_percentage  token_to_sol_percentage  \\\n",
      "0                         0                   0.5000                   0.5000   \n",
      "1                       345                   0.9380                   0.0081   \n",
      "2                         0                   0.4983                   0.5017   \n",
      "3                         0                   0.5001                   0.4999   \n",
      "4                         5                   0.5093                   0.4905   \n",
      "\n",
      "   token_to_token_percentage  buy_sell_ratio  \n",
      "0                     0.0000          1.0000  \n",
      "1                     0.0538        115.5980  \n",
      "2                     0.0000          0.9932  \n",
      "3                     0.0000          1.0004  \n",
      "4                     0.0002          1.0383  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check trader_features table structure\n",
    "trader_features_info = con.execute('DESCRIBE trader_features').fetchdf()\n",
    "print(\"trader_features table structure:\")\n",
    "print(trader_features_info)\n",
    "\n",
    "# Sample data\n",
    "trader_features_sample = con.execute('SELECT * FROM trader_features LIMIT 5').fetchdf()\n",
    "print(\"\\ntrader_features sample:\")\n",
    "print(trader_features_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trader_coin_performance table structure:\n",
      "              column_name column_type null   key default extra\n",
      "0                 swapper     VARCHAR  YES  None    None  None\n",
      "1                    mint     VARCHAR  YES  None    None  None\n",
      "2       sol_spent_on_coin      DOUBLE  YES  None    None  None\n",
      "3  sol_received_from_coin      DOUBLE  YES  None    None  None\n",
      "4              buy_trades      BIGINT  YES  None    None  None\n",
      "5             sell_trades      BIGINT  YES  None    None  None\n",
      "6       total_coin_trades      BIGINT  YES  None    None  None\n",
      "7    net_sol_pnl_per_coin      DOUBLE  YES  None    None  None\n",
      "8             roi_on_coin      DOUBLE  YES  None    None  None\n",
      "9    hours_active_on_coin      DOUBLE  YES  None    None  None\n",
      "\n",
      "trader_coin_performance sample:\n",
      "                                        swapper  \\\n",
      "0  4DbAcLDyhCLX7rKPx55xTQA6D8w2poSg3xwW6NzozAAe   \n",
      "1  4DbAcLDyhCLX7rKPx55xTQA6D8w2poSg3xwW6NzozAAe   \n",
      "2  4DbAcLDyhCLX7rKPx55xTQA6D8w2poSg3xwW6NzozAAe   \n",
      "3  HV1KXxWFaSeriyFvXyx48FqG9BoFbfinB8njCJonqP7K   \n",
      "4  AupTbxArPau5H97izWurgska1hEvFNrYM1U8Yy9ijrWU   \n",
      "\n",
      "                                           mint  sol_spent_on_coin  \\\n",
      "0   PSG1RJpLVmHPwNZm7kP7UrDByYPUHzh6Q4ffA3TYfeo        294671.0287   \n",
      "1   LiNgojrWAuWjsLTHghPwi23b46bMDUQhwmg5aWkDqof        228000.0000   \n",
      "2   Pain8LjdMXzL1CLMwy2H6cvdUNCDiWgCWwYBYyrj86J        179445.7268   \n",
      "3  ECY31gWwxy4s2VnMkYhmqDkrV75KrwR2yTtsnrnSpump         58609.7887   \n",
      "4   xyzR4s6H724bUq6q7MTqWxUnhi8LM5fiKKUq38h8M1P          6000.0000   \n",
      "\n",
      "   sol_received_from_coin  buy_trades  sell_trades  total_coin_trades  \\\n",
      "0             147200.0172        1286          614               1900   \n",
      "1             113909.8603         228          134                362   \n",
      "2              89651.9550         638          303                941   \n",
      "3               1716.4313       16263          248              22900   \n",
      "4              57111.8536           1           19                 20   \n",
      "\n",
      "   net_sol_pnl_per_coin  roi_on_coin  hours_active_on_coin  \n",
      "0          -147471.0115      -0.5005                  2.02  \n",
      "1          -114090.1397      -0.5004                  0.37  \n",
      "2           -89793.7718      -0.5004                  0.67  \n",
      "3           -56893.3574      -0.9707                 22.69  \n",
      "4            51111.8536       8.5186                  0.64  \n"
     ]
    }
   ],
   "source": [
    "# Check trader_coin_performance table structure  \n",
    "performance_info = con.execute('DESCRIBE trader_coin_performance').fetchdf()\n",
    "print(\"trader_coin_performance table structure:\")\n",
    "print(performance_info)\n",
    "\n",
    "# Sample data\n",
    "performance_sample = con.execute('SELECT * FROM trader_coin_performance LIMIT 5').fetchdf()\n",
    "print(\"\\ntrader_coin_performance sample:\")\n",
    "print(performance_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine First Two Hours Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trader_coin_features table structure:\n",
      "                   column_name column_type null   key default extra\n",
      "0                    trader_id     VARCHAR  YES  None    None  None\n",
      "1                      coin_id     VARCHAR  YES  None    None  None\n",
      "2                  trade_count      BIGINT  YES  None    None  None\n",
      "3              trades_per_hour      DOUBLE  YES  None    None  None\n",
      "4            time_span_minutes      DOUBLE  YES  None    None  None\n",
      "5          total_volume_traded      DOUBLE  YES  None    None  None\n",
      "6               avg_trade_size      DOUBLE  YES  None    None  None\n",
      "7                trade_size_cv      DOUBLE  YES  None    None  None\n",
      "8           largest_trade_size      DOUBLE  YES  None    None  None\n",
      "9         volume_concentration      DOUBLE  YES  None    None  None\n",
      "10        unique_trading_pairs      BIGINT  YES  None    None  None\n",
      "11       sol_involvement_ratio       FLOAT  YES  None    None  None\n",
      "12                   buy_ratio       FLOAT  YES  None    None  None\n",
      "13          round_number_ratio       FLOAT  YES  None    None  None\n",
      "14        trade_size_diversity       FLOAT  YES  None    None  None\n",
      "15  avg_seconds_between_trades      DOUBLE  YES  None    None  None\n",
      "16         first_trade_minutes      DOUBLE  YES  None    None  None\n",
      "\n",
      "trader_coin_features sample:\n",
      "                                      trader_id  \\\n",
      "0  A1GJZn9QWnEryKo8DU847rjgvAfj7AmWgc9SzaFJkJ9x   \n",
      "1  3gLQQ7faiVGdRoyeAAfk1q6dbs2DLGeTJF4QYuJXdz4z   \n",
      "2  HaW2bpEwppksxqhfaPXjv5P95KazZ4HN3G5Vzd2K7gYW   \n",
      "3  DkQFFRRstsx94P5sa3WSSU2wSPNgzWNUuQb93GKFMX2v   \n",
      "4  6XAP1QSYXsgXeLi63BDcXRySA1nw7R7mgpgdVuWLiAG3   \n",
      "\n",
      "                                        coin_id  trade_count  trades_per_hour  \\\n",
      "0  BDW8YHasD3NSDjSHU9Xy6KXtshGayMGQfj5bJpLcpump            2              1.0   \n",
      "1  BDW8YHasD3NSDjSHU9Xy6KXtshGayMGQfj5bJpLcpump            1              0.5   \n",
      "2  BDW8YHasD3NSDjSHU9Xy6KXtshGayMGQfj5bJpLcpump            7              3.5   \n",
      "3  BDW8YHasD3NSDjSHU9Xy6KXtshGayMGQfj5bJpLcpump            4              2.0   \n",
      "4  BDW8YHasD3NSDjSHU9Xy6KXtshGayMGQfj5bJpLcpump            6              3.0   \n",
      "\n",
      "   time_span_minutes  total_volume_traded  avg_trade_size  trade_size_cv  \\\n",
      "0           1.883333          9267.602275     4633.801137       1.413908   \n",
      "1           0.000000             0.198000        0.198000            NaN   \n",
      "2          66.050000          6660.448857      951.492694       1.374355   \n",
      "3          68.100000           185.985808       46.496452       1.154452   \n",
      "4          91.416667          3579.160053      596.526675       1.128975   \n",
      "\n",
      "   largest_trade_size  volume_concentration  unique_trading_pairs  \\\n",
      "0         9266.602275              0.999892                     2   \n",
      "1            0.198000              1.000000                     1   \n",
      "2         3066.194921              0.460359                     2   \n",
      "3           92.982904              0.499946                     2   \n",
      "4         1342.072520              0.374969                     2   \n",
      "\n",
      "   sol_involvement_ratio  buy_ratio  round_number_ratio  trade_size_diversity  \\\n",
      "0                    1.0   0.500000                 0.5                   1.0   \n",
      "1                    1.0   1.000000                 0.0                   1.0   \n",
      "2                    1.0   0.571429                 0.0                   1.0   \n",
      "3                    1.0   0.500000                 0.5                   0.5   \n",
      "4                    1.0   0.500000                 0.5                   0.5   \n",
      "\n",
      "   avg_seconds_between_trades  first_trade_minutes  \n",
      "0                       113.0            18.600000  \n",
      "1                         0.0            18.883333  \n",
      "2                       660.5            10.766667  \n",
      "3                      1362.0            21.400000  \n",
      "4                      1097.0             9.483333  \n"
     ]
    }
   ],
   "source": [
    "# Check if trader_coin_features table exists (from previous notebook)\n",
    "try:\n",
    "    coin_features_info = con.execute('DESCRIBE trader_coin_first_two_hours_features').fetchdf()\n",
    "    print(\"trader_coin_features table structure:\")\n",
    "    print(coin_features_info)\n",
    "    \n",
    "    # Sample data\n",
    "    coin_features_sample = con.execute('SELECT * FROM trader_coin_first_two_hours_features LIMIT 5').fetchdf()\n",
    "    print(\"\\ntrader_coin_features sample:\")\n",
    "    print(coin_features_sample)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"trader_coin_first_two_hours_features table not found: {e}\")\n",
    "    print(\"Need to create this table from the previous notebook first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trader-level PnL features...\n",
      "Generated features for 10,060,972 traders\n",
      "\n",
      "Sample data:\n",
      "                                        swapper  total_positions  win_rate  \\\n",
      "0  DLcw9YVYTsgBbAPBfXKV8JS6KRXo6VgLFDM5o1ydZV7R                1       1.0   \n",
      "1  AMd5bXpf5wh3wrKkDa4c18jNo147WBFsj55rvJvXzsjT                1       1.0   \n",
      "2  Gwc7ApjwTaFHC6HB7cWEFjsqaayZoAqdvSsiTwbfZv8m                1       1.0   \n",
      "3  2mzEJFRa9UXvkLBeJMH16j6GUyDxPLnkDVoUUt1MLeej                1       1.0   \n",
      "4  6Qcx9qWCb8UPZv6R6i4j8CWzxrEYtsodPTNKrZzG7M2q                1       1.0   \n",
      "5  GUw1Av3EGLMtGJUUY4RgQpR4SR8N2EMyowtD8vuNs8ab                1       1.0   \n",
      "6  9Tqaa1V36pBHtNXrZS4xrLru8HbV38pRRyh4YxR6bxUw                1       1.0   \n",
      "7  CHj3vHyMhF6DF3VkwhzgK833o7uvsN7CrPVyUdmbFo5E                1       1.0   \n",
      "8  9DtTbUgdzFoKvaM7ALpB8LhYHf4Q7ggjphsBHotREj8z                1       1.0   \n",
      "9  HiiqhjDF8hgeBbnbZNdkyjx6Wvy2oefvh85GokojbRnN                1       1.0   \n",
      "\n",
      "   avg_pnl_per_position    avg_roi  overall_buy_sell_ratio  \n",
      "0            37248.1004        NaN                0.000000  \n",
      "1            23288.6578     8.5778                0.003425  \n",
      "2            23099.6430        NaN                0.000000  \n",
      "3            22775.5147     1.3477                0.035714  \n",
      "4            21702.6165     1.2556                0.066667  \n",
      "5            21511.0858   307.3012                0.013158  \n",
      "6            21329.8748  3949.9768                0.002165  \n",
      "7            19619.5183        NaN                0.000000  \n",
      "8            16023.0650  2972.7393                0.007874  \n",
      "9            15840.8934     3.7759                0.010870  \n",
      "Generated features for 10,060,972 traders\n",
      "\n",
      "Sample data:\n",
      "                                        swapper  total_positions  win_rate  \\\n",
      "0  DLcw9YVYTsgBbAPBfXKV8JS6KRXo6VgLFDM5o1ydZV7R                1       1.0   \n",
      "1  AMd5bXpf5wh3wrKkDa4c18jNo147WBFsj55rvJvXzsjT                1       1.0   \n",
      "2  Gwc7ApjwTaFHC6HB7cWEFjsqaayZoAqdvSsiTwbfZv8m                1       1.0   \n",
      "3  2mzEJFRa9UXvkLBeJMH16j6GUyDxPLnkDVoUUt1MLeej                1       1.0   \n",
      "4  6Qcx9qWCb8UPZv6R6i4j8CWzxrEYtsodPTNKrZzG7M2q                1       1.0   \n",
      "5  GUw1Av3EGLMtGJUUY4RgQpR4SR8N2EMyowtD8vuNs8ab                1       1.0   \n",
      "6  9Tqaa1V36pBHtNXrZS4xrLru8HbV38pRRyh4YxR6bxUw                1       1.0   \n",
      "7  CHj3vHyMhF6DF3VkwhzgK833o7uvsN7CrPVyUdmbFo5E                1       1.0   \n",
      "8  9DtTbUgdzFoKvaM7ALpB8LhYHf4Q7ggjphsBHotREj8z                1       1.0   \n",
      "9  HiiqhjDF8hgeBbnbZNdkyjx6Wvy2oefvh85GokojbRnN                1       1.0   \n",
      "\n",
      "   avg_pnl_per_position    avg_roi  overall_buy_sell_ratio  \n",
      "0            37248.1004        NaN                0.000000  \n",
      "1            23288.6578     8.5778                0.003425  \n",
      "2            23099.6430        NaN                0.000000  \n",
      "3            22775.5147     1.3477                0.035714  \n",
      "4            21702.6165     1.2556                0.066667  \n",
      "5            21511.0858   307.3012                0.013158  \n",
      "6            21329.8748  3949.9768                0.002165  \n",
      "7            19619.5183        NaN                0.000000  \n",
      "8            16023.0650  2972.7393                0.007874  \n",
      "9            15840.8934     3.7759                0.010870  \n"
     ]
    }
   ],
   "source": [
    "# Create trader-level PnL features from coin performance data\n",
    "pnl_features_query = \"\"\"\n",
    "SELECT \n",
    "    swapper,\n",
    "    COUNT(*) as total_positions,\n",
    "    \n",
    "    -- Win rate\n",
    "    ROUND(SUM(CASE WHEN net_sol_pnl_per_coin > 0 THEN 1 ELSE 0 END)::FLOAT / COUNT(*), 4) as win_rate,\n",
    "    \n",
    "    -- Average PnL per position\n",
    "    ROUND(AVG(net_sol_pnl_per_coin), 4) as avg_pnl_per_position,\n",
    "    \n",
    "    -- Average ROI (only for positions with actual spending)\n",
    "    ROUND(AVG(CASE WHEN roi_on_coin IS NOT NULL THEN roi_on_coin END), 4) as avg_roi,\n",
    "\n",
    "    sum(buy_trades)::FLOAT/sum(sell_trades)::FLOAT as overall_buy_sell_ratio\n",
    "    \n",
    "FROM trader_coin_performance \n",
    "GROUP BY swapper\n",
    "ORDER BY avg_pnl_per_position DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating trader-level PnL features...\")\n",
    "trader_pnl_features = con.execute(pnl_features_query).fetchdf()\n",
    "\n",
    "print(f\"Generated features for {len(trader_pnl_features):,} traders\")\n",
    "print(\"\\nSample data:\")\n",
    "print(trader_pnl_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging trader features with PnL features...\n",
      "Loaded 10,060,972 traders from trader_features\n",
      "Loaded 10,060,972 traders from trader_features\n",
      "Merged dataset: 10,060,972 traders with 34 features\n",
      "Features added: total_positions, win_rate, avg_pnl_per_position, avg_roi\n",
      "\n",
      "Missing values in new PnL features:\n",
      "  total_positions: 0 missing (0.0%)\n",
      "  win_rate: 0 missing (0.0%)\n",
      "  avg_pnl_per_position: 0 missing (0.0%)\n",
      "  avg_roi: 944,706 missing (9.4%)\n",
      "\n",
      "Sample of merged data:\n",
      "                                        swapper  total_trades_count  \\\n",
      "0   arsc4jbDnzaqcCLByyGo7fg7S2SmcFsWUzQuDtLZh2y              151632   \n",
      "1  HV1KXxWFaSeriyFvXyx48FqG9BoFbfinB8njCJonqP7K             1279901   \n",
      "2  8MqRTAQnjhDYH7TWS1b1DjFog4CLZfySWE5cZeotG2VW              105378   \n",
      "3  AD65fgYti96iSSzSPaNazV9Bs29m7JbNomGjG4Cp5WFS               68131   \n",
      "4  D4zVhwuUsFbcaty7wJhNEZ7VEwPHXQ5d2heXPxM5yWhL               74918   \n",
      "\n",
      "   total_sol_spent  total_sol_received  avg_sol_trade_size  \\\n",
      "0     3.165754e+06        3.209894e+06             41.7557   \n",
      "1     1.562690e+06        2.439516e+04              1.3016   \n",
      "2     1.221408e+06        1.237385e+06             23.2609   \n",
      "3     1.027367e+06        1.043267e+06             30.1528   \n",
      "4     8.597928e+05        8.579472e+05             22.5348   \n",
      "\n",
      "   median_sol_trade_size  max_single_sol_trade  min_sol_trade_size  \\\n",
      "0                15.4261             2970.0000              0.0001   \n",
      "1                 0.1759             2330.7915              0.0000   \n",
      "2                 9.4538             2024.6330              0.0001   \n",
      "3                10.3493             2970.0000              0.0000   \n",
      "4                 9.9653             1295.2484              0.0000   \n",
      "\n",
      "   sol_trade_size_std_dev  trade_size_coefficient_variation  ...  \\\n",
      "0                107.4546                            2.5734  ...   \n",
      "1                  7.5630                            5.8106  ...   \n",
      "2                 54.1730                            2.3289  ...   \n",
      "3                 96.0312                            3.1848  ...   \n",
      "4                 48.0948                            2.1342  ...   \n",
      "\n",
      "   unique_from_tokens_non_sol  unique_to_tokens_non_sol  \\\n",
      "0                           0                         0   \n",
      "1                          41                       345   \n",
      "2                           0                         0   \n",
      "3                           0                         0   \n",
      "4                           4                         5   \n",
      "\n",
      "   sol_to_token_percentage  token_to_sol_percentage  \\\n",
      "0                   0.5000                   0.5000   \n",
      "1                   0.9380                   0.0081   \n",
      "2                   0.4983                   0.5017   \n",
      "3                   0.5001                   0.4999   \n",
      "4                   0.5093                   0.4905   \n",
      "\n",
      "   token_to_token_percentage  buy_sell_ratio  total_positions  win_rate  \\\n",
      "0                     0.0000          1.0000              264    1.0000   \n",
      "1                     0.0538        115.5980             3321    0.0018   \n",
      "2                     0.0000          0.9932             1349    0.9978   \n",
      "3                     0.0000          1.0004              553    0.9964   \n",
      "4                     0.0002          1.0383             1270    0.4976   \n",
      "\n",
      "   avg_pnl_per_position  avg_roi  \n",
      "0              167.1962   0.1520  \n",
      "1             -463.2022  -0.9922  \n",
      "2               11.8435   0.1188  \n",
      "3               28.7525  20.8891  \n",
      "4               -1.4532  -0.0885  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Merged dataset: 10,060,972 traders with 34 features\n",
      "Features added: total_positions, win_rate, avg_pnl_per_position, avg_roi\n",
      "\n",
      "Missing values in new PnL features:\n",
      "  total_positions: 0 missing (0.0%)\n",
      "  win_rate: 0 missing (0.0%)\n",
      "  avg_pnl_per_position: 0 missing (0.0%)\n",
      "  avg_roi: 944,706 missing (9.4%)\n",
      "\n",
      "Sample of merged data:\n",
      "                                        swapper  total_trades_count  \\\n",
      "0   arsc4jbDnzaqcCLByyGo7fg7S2SmcFsWUzQuDtLZh2y              151632   \n",
      "1  HV1KXxWFaSeriyFvXyx48FqG9BoFbfinB8njCJonqP7K             1279901   \n",
      "2  8MqRTAQnjhDYH7TWS1b1DjFog4CLZfySWE5cZeotG2VW              105378   \n",
      "3  AD65fgYti96iSSzSPaNazV9Bs29m7JbNomGjG4Cp5WFS               68131   \n",
      "4  D4zVhwuUsFbcaty7wJhNEZ7VEwPHXQ5d2heXPxM5yWhL               74918   \n",
      "\n",
      "   total_sol_spent  total_sol_received  avg_sol_trade_size  \\\n",
      "0     3.165754e+06        3.209894e+06             41.7557   \n",
      "1     1.562690e+06        2.439516e+04              1.3016   \n",
      "2     1.221408e+06        1.237385e+06             23.2609   \n",
      "3     1.027367e+06        1.043267e+06             30.1528   \n",
      "4     8.597928e+05        8.579472e+05             22.5348   \n",
      "\n",
      "   median_sol_trade_size  max_single_sol_trade  min_sol_trade_size  \\\n",
      "0                15.4261             2970.0000              0.0001   \n",
      "1                 0.1759             2330.7915              0.0000   \n",
      "2                 9.4538             2024.6330              0.0001   \n",
      "3                10.3493             2970.0000              0.0000   \n",
      "4                 9.9653             1295.2484              0.0000   \n",
      "\n",
      "   sol_trade_size_std_dev  trade_size_coefficient_variation  ...  \\\n",
      "0                107.4546                            2.5734  ...   \n",
      "1                  7.5630                            5.8106  ...   \n",
      "2                 54.1730                            2.3289  ...   \n",
      "3                 96.0312                            3.1848  ...   \n",
      "4                 48.0948                            2.1342  ...   \n",
      "\n",
      "   unique_from_tokens_non_sol  unique_to_tokens_non_sol  \\\n",
      "0                           0                         0   \n",
      "1                          41                       345   \n",
      "2                           0                         0   \n",
      "3                           0                         0   \n",
      "4                           4                         5   \n",
      "\n",
      "   sol_to_token_percentage  token_to_sol_percentage  \\\n",
      "0                   0.5000                   0.5000   \n",
      "1                   0.9380                   0.0081   \n",
      "2                   0.4983                   0.5017   \n",
      "3                   0.5001                   0.4999   \n",
      "4                   0.5093                   0.4905   \n",
      "\n",
      "   token_to_token_percentage  buy_sell_ratio  total_positions  win_rate  \\\n",
      "0                     0.0000          1.0000              264    1.0000   \n",
      "1                     0.0538        115.5980             3321    0.0018   \n",
      "2                     0.0000          0.9932             1349    0.9978   \n",
      "3                     0.0000          1.0004              553    0.9964   \n",
      "4                     0.0002          1.0383             1270    0.4976   \n",
      "\n",
      "   avg_pnl_per_position  avg_roi  \n",
      "0              167.1962   0.1520  \n",
      "1             -463.2022  -0.9922  \n",
      "2               11.8435   0.1188  \n",
      "3               28.7525  20.8891  \n",
      "4               -1.4532  -0.0885  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge trader_features with trader_pnl_features\n",
    "print(\"Merging trader features with PnL features...\")\n",
    "\n",
    "# Load trader_features from database\n",
    "trader_features = con.execute('SELECT * FROM trader_features').fetchdf()\n",
    "print(f\"Loaded {len(trader_features):,} traders from trader_features\")\n",
    "\n",
    "# Merge the datasets\n",
    "merged_features = trader_features.merge(\n",
    "    trader_pnl_features[['swapper', 'total_positions', 'win_rate', 'avg_pnl_per_position', 'avg_roi']],\n",
    "    on='swapper',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {len(merged_features):,} traders with {len(merged_features.columns)} features\")\n",
    "print(f\"Features added: total_positions, win_rate, avg_pnl_per_position, avg_roi\")\n",
    "\n",
    "# Check for missing values in new features\n",
    "print(\"\\nMissing values in new PnL features:\")\n",
    "pnl_cols = ['total_positions', 'win_rate', 'avg_pnl_per_position', 'avg_roi']\n",
    "for col in pnl_cols:\n",
    "    missing = merged_features[col].isna().sum()\n",
    "    print(f\"  {col}: {missing:,} missing ({missing/len(merged_features)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nSample of merged data:\")\n",
    "print(merged_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation Plan for All 34 Features\n",
    "\n",
    "Based on the comprehensive feature set from trader_feature_engineering.md, here's a detailed plan for preparing all 34 trader-level features for clustering analysis:\n",
    "\n",
    "### Feature Categories & Transformation Strategy\n",
    "\n",
    "#### 1. Volume & Scale Features (11 features)\n",
    "**High skew, need log transformation**\n",
    "- `total_trades_count`: Log1p transform (handles 0 values)\n",
    "- `total_sol_spent`, `total_sol_received`: Log1p transform \n",
    "- `avg_sol_trade_size`, `median_sol_trade_size`: Log1p transform\n",
    "- `max_single_sol_trade`: Log1p transform (captures whale behavior)\n",
    "- `min_sol_trade_size`: Log1p transform (keeps 0 values as-is, log1p handles them naturally)\n",
    "- `sol_trade_size_std_dev`: Log1p transform\n",
    "- `trade_size_coefficient_variation`: Already normalized ratio, StandardScaler\n",
    "- `net_sol_pnl`: Handle negative values → Signed log transform\n",
    "\n",
    "#### 2. Diversification Features (3 features) \n",
    "**Count-based, use sqrt transformation**\n",
    "- `unique_coins_traded`: Sqrt transform (reduces right skew)\n",
    "- `avg_trades_per_coin`: Log1p transform\n",
    "- `trade_concentration_ratio`: Already 0-1 bounded, StandardScaler\n",
    "\n",
    "#### 3. Timing & Behavioral Features (6 features)\n",
    "**Mixed scales and distributions**\n",
    "- `trading_span_days`: Log1p transform (wide range: 0-1509 days)\n",
    "- `trades_per_day`: Log1p transform (high variance)\n",
    "- `avg_hours_between_trades`: Fill NULL with (max_value + 1), then Log1p transform + binary indicator `is_multi_trader`\n",
    "- `active_hours`, `active_days`: Sqrt transform (count data)\n",
    "- `trades_per_active_hour`: Log1p transform (0-36027 range)\n",
    "\n",
    "#### 4. Bot Detection Features (1 feature)\n",
    "**Already normalized**\n",
    "- `round_number_preference`: 0-1 bounded, StandardScaler only\n",
    "\n",
    "#### 5. Non-SOL Trade Features (10 features)\n",
    "**Mix of counts and percentages**\n",
    "- `sol_to_token_trades`, `token_to_sol_trades`, `token_to_token_trades`: Log1p transform\n",
    "- `unique_from_tokens_non_sol`, `unique_to_tokens_non_sol`: Sqrt transform\n",
    "- `sol_to_token_percentage`, `token_to_sol_percentage`, `token_to_token_percentage`: Already 0-1, StandardScaler\n",
    "- `buy_sell_ratio`: Log1p transform (can be very large)\n",
    "\n",
    "#### 6. Aggregated Performance Features (4 features)\n",
    "**Mixed distributions, some with missing values**\n",
    "- `total_positions`: Log1p transform\n",
    "- `win_rate`: Already 0-1 bounded, StandardScaler\n",
    "- `avg_pnl_per_position`: Signed log transform (handles negatives)\n",
    "- `avg_roi`: Fill missing with (max_value + 1), then StandardScaler + binary indicator `has_buy_history`\n",
    "\n",
    "### Missing Value Strategy\n",
    "\n",
    "#### 1. Insider Trade Detection (`avg_roi`)\n",
    "- **Missing values (9.4%)**: These are insider trades (sell-only, no buy cost basis)\n",
    "- **Solution**: \n",
    "  - Fill missing with `max(avg_roi) + 1` to clearly separate from normal range\n",
    "  - Create binary feature: `has_buy_history` (1 = normal trader, 0 = insider/airdrop)\n",
    "  - Apply StandardScaler to filled values\n",
    "\n",
    "#### 2. Single-Trade Account Handling (`avg_hours_between_trades`)\n",
    "- **NULL values**: Single-trade accounts (can't calculate interval)\n",
    "- **Solution**:\n",
    "  - Fill NULL with `max(avg_hours_between_trades) + 1` \n",
    "  - Create binary feature: `is_multi_trader` (1 = multiple trades, 0 = single trade)\n",
    "  - Apply Log1p transform then StandardScaler\n",
    "\n",
    "#### 3. Zero Value Handling (`min_sol_trade_size`)\n",
    "- **Zero values**: Dust trades, airdrops, MEV residuals - valid behavioral signal\n",
    "- **Solution**: Keep 0 values, apply Log1p transform (handles 0 naturally)\n",
    "- **No binary indicator needed**: 0 is meaningful information about trading behavior\n",
    "\n",
    "### Final Pipeline Steps\n",
    "- Original 34 features + 2 binary indicators = **36 features total**\n",
    "- Apply transformations → StandardScaler for final normalization\n",
    "- All features remain numerical (no categorical encoding complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Applying feature transformations...\n",
      "   Applied log1p transform to 8 volume features + signed log to net_sol_pnl\n",
      "   Applied sqrt to unique_coins_traded, log1p to avg_trades_per_coin\n",
      "   Applied log1p to 4 timing features, sqrt to 2 count features\n",
      "   Applied log1p to 4 trade count features, sqrt to token diversity features\n",
      "   Applied log1p to total_positions, signed log to avg_pnl_per_position\n",
      "   Transformations completed.\n",
      "\n",
      "Transformed dataset shape: (10060972, 34)\n",
      "Final feature count: 34 (34 original + 2 binary indicators)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Apply transformations according to the plan\n",
    "print(\"\\n3. Applying feature transformations...\")\n",
    "df_prep = merged_features.copy()\n",
    "# Helper function for signed log transform (handles negative values)\n",
    "def signed_log_transform(x):\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "# 1. Volume & Scale Features - Log1p transform (except coefficient of variation)\n",
    "volume_log_features = [\n",
    "    'total_trades_count', 'total_sol_spent', 'total_sol_received',\n",
    "    'avg_sol_trade_size', 'median_sol_trade_size', 'max_single_sol_trade',\n",
    "    'min_sol_trade_size', 'sol_trade_size_std_dev'\n",
    "]\n",
    "\n",
    "for feature in volume_log_features:\n",
    "    if feature in df_prep.columns:\n",
    "        df_prep[feature] = np.log1p(df_prep[feature])\n",
    "\n",
    "# Handle net_sol_pnl with signed log transform\n",
    "if 'net_sol_pnl' in df_prep.columns:\n",
    "    df_prep['net_sol_pnl'] = signed_log_transform(df_prep['net_sol_pnl'])\n",
    "\n",
    "print(f\"   Applied log1p transform to {len(volume_log_features)} volume features + signed log to net_sol_pnl\")\n",
    "\n",
    "# 2. Diversification Features - Mixed transforms\n",
    "if 'unique_coins_traded' in df_prep.columns:\n",
    "    df_prep['unique_coins_traded'] = np.sqrt(df_prep['unique_coins_traded'])\n",
    "if 'avg_trades_per_coin' in df_prep.columns:\n",
    "    df_prep['avg_trades_per_coin'] = np.log1p(df_prep['avg_trades_per_coin'])\n",
    "# trade_concentration_ratio stays as-is (already 0-1 bounded)\n",
    "\n",
    "print(\"   Applied sqrt to unique_coins_traded, log1p to avg_trades_per_coin\")\n",
    "\n",
    "# 3. Timing Features - Mixed transforms  \n",
    "timing_log_features = [\n",
    "    'trading_span_days', 'trades_per_day', 'avg_hours_between_trades', 'trades_per_active_hour'\n",
    "]\n",
    "timing_sqrt_features = ['active_hours', 'active_days']\n",
    "\n",
    "for feature in timing_log_features:\n",
    "    if feature in df_prep.columns:\n",
    "        df_prep[feature] = np.log1p(df_prep[feature])\n",
    "\n",
    "for feature in timing_sqrt_features:\n",
    "    if feature in df_prep.columns:\n",
    "        df_prep[feature] = np.sqrt(df_prep[feature])\n",
    "\n",
    "print(f\"   Applied log1p to {len(timing_log_features)} timing features, sqrt to {len(timing_sqrt_features)} count features\")\n",
    "\n",
    "# 4. round_number_preference stays as-is (already 0-1 bounded)\n",
    "\n",
    "# 5. Non-SOL Trade Features - Mixed transforms\n",
    "trade_log_features = [\n",
    "    'sol_to_token_trades', 'token_to_sol_trades', 'token_to_token_trades', 'buy_sell_ratio'\n",
    "]\n",
    "trade_sqrt_features = ['unique_from_tokens_non_sol', 'unique_to_tokens_non_sol']\n",
    "\n",
    "for feature in trade_log_features:\n",
    "    if feature in df_prep.columns:\n",
    "        df_prep[feature] = np.log1p(df_prep[feature])\n",
    "\n",
    "for feature in trade_sqrt_features:\n",
    "    if feature in df_prep.columns:\n",
    "        df_prep[feature] = np.sqrt(df_prep[feature])\n",
    "\n",
    "print(f\"   Applied log1p to {len(trade_log_features)} trade count features, sqrt to token diversity features\")\n",
    "# sol_to_token_percentage, token_to_sol_percentage, token_to_token_percentage stay as-is (0-1 bounded)\n",
    "\n",
    "# 6. Performance Features - Mixed transforms\n",
    "if 'total_positions' in df_prep.columns:\n",
    "    df_prep['total_positions'] = np.log1p(df_prep['total_positions'])\n",
    "if 'avg_pnl_per_position' in df_prep.columns:\n",
    "    df_prep['avg_pnl_per_position'] = signed_log_transform(df_prep['avg_pnl_per_position'])\n",
    "# win_rate and avg_roi stay as-is for now (will be standardized)\n",
    "\n",
    "print(\"   Applied log1p to total_positions, signed log to avg_pnl_per_position\")\n",
    "print(\"   Transformations completed.\")\n",
    "\n",
    "print(f\"\\nTransformed dataset shape: {df_prep.shape}\")\n",
    "print(f\"Final feature count: {len(df_prep.columns)} (34 original + 2 binary indicators)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPLEMENTING DATA PREPARATION PLAN ===\n",
      "\n",
      "Processing 34 features...\n",
      "\n",
      "1. Handling missing values...\n",
      "   avg_roi: filled 944,706 missing values with 498888926625.00\n",
      "   avg_hours_between_trades: filled 3,110,879 missing values with 11.49\n",
      "   Remaining missing values: 20925350\n",
      "\n",
      "After missing value handling: 36 features\n",
      "Added binary indicators: has_buy_history, is_multi_trader\n"
     ]
    }
   ],
   "source": [
    "# Implementation of Data Preparation Plan\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"=== IMPLEMENTING DATA PREPARATION PLAN ===\")\n",
    "#print(f\"Starting with {len(merged_features)} traders and {len(merged_features.columns)} features\")\n",
    "\n",
    "# Create a copy for processing\n",
    "#df_prep = merged_features.copy()\n",
    "\n",
    "# Remove the swapper ID column for processing\n",
    "#df_prep = df_prep.drop('swapper', axis=1)\n",
    "\n",
    "print(f\"\\nProcessing {len(df_prep.columns)} features...\")\n",
    "\n",
    "# Step 1: Handle missing values with max+1 strategy and create binary indicators\n",
    "print(\"\\n1. Handling missing values...\")\n",
    "\n",
    "# avg_roi: Fill missing with max+1, create binary indicator\n",
    "avg_roi_max = df_prep['avg_roi'].max()\n",
    "df_prep['has_buy_history'] = (~df_prep['avg_roi'].isna()).astype(int)\n",
    "df_prep['avg_roi'] = df_prep['avg_roi'].fillna(avg_roi_max + 1)\n",
    "print(f\"   avg_roi: filled {(~merged_features['avg_roi'].notna()).sum():,} missing values with {avg_roi_max + 1:.2f}\")\n",
    "\n",
    "# avg_hours_between_trades: Fill NULL with max+1, create binary indicator  \n",
    "hours_max = df_prep['avg_hours_between_trades'].max()\n",
    "df_prep['is_multi_trader'] = (~df_prep['avg_hours_between_trades'].isna()).astype(int)\n",
    "df_prep['avg_hours_between_trades'] = df_prep['avg_hours_between_trades'].fillna(hours_max + 1)\n",
    "print(f\"   avg_hours_between_trades: filled {(~merged_features['avg_hours_between_trades'].notna()).sum():,} missing values with {hours_max + 1:.2f}\")\n",
    "\n",
    "# Check for any remaining missing values\n",
    "remaining_missing = df_prep.isnull().sum().sum()\n",
    "print(f\"   Remaining missing values: {remaining_missing}\")\n",
    "\n",
    "print(f\"\\nAfter missing value handling: {len(df_prep.columns)} features\")\n",
    "print(f\"Added binary indicators: has_buy_history, is_multi_trader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Further data normalization for larger numerical ones\n",
    "\n",
    "Some of the numerical features may have extreme values, which caused clustering model training warnings, we should normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swapper</th>\n",
       "      <th>total_trades_count</th>\n",
       "      <th>total_sol_spent</th>\n",
       "      <th>total_sol_received</th>\n",
       "      <th>avg_sol_trade_size</th>\n",
       "      <th>median_sol_trade_size</th>\n",
       "      <th>max_single_sol_trade</th>\n",
       "      <th>min_sol_trade_size</th>\n",
       "      <th>sol_trade_size_std_dev</th>\n",
       "      <th>trade_size_coefficient_variation</th>\n",
       "      <th>...</th>\n",
       "      <th>sol_to_token_percentage</th>\n",
       "      <th>token_to_sol_percentage</th>\n",
       "      <th>token_to_token_percentage</th>\n",
       "      <th>buy_sell_ratio</th>\n",
       "      <th>total_positions</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>avg_pnl_per_position</th>\n",
       "      <th>avg_roi</th>\n",
       "      <th>has_buy_history</th>\n",
       "      <th>is_multi_trader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arsc4jbDnzaqcCLByyGo7fg7S2SmcFsWUzQuDtLZh2y</td>\n",
       "      <td>11.929218</td>\n",
       "      <td>14.967902</td>\n",
       "      <td>14.981749</td>\n",
       "      <td>3.755503</td>\n",
       "      <td>2.798872</td>\n",
       "      <td>7.996654</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.686332</td>\n",
       "      <td>2.5734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.579730</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.125131</td>\n",
       "      <td>1.520000e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV1KXxWFaSeriyFvXyx48FqG9BoFbfinB8njCJonqP7K</td>\n",
       "      <td>14.062294</td>\n",
       "      <td>14.261920</td>\n",
       "      <td>10.102181</td>\n",
       "      <td>0.833605</td>\n",
       "      <td>0.162034</td>\n",
       "      <td>7.754392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.147451</td>\n",
       "      <td>5.8106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>4.758732</td>\n",
       "      <td>8.108322</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-6.140320</td>\n",
       "      <td>-9.922000e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8MqRTAQnjhDYH7TWS1b1DjFog4CLZfySWE5cZeotG2VW</td>\n",
       "      <td>11.565319</td>\n",
       "      <td>14.015515</td>\n",
       "      <td>14.028511</td>\n",
       "      <td>3.188866</td>\n",
       "      <td>2.346966</td>\n",
       "      <td>7.613638</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.010474</td>\n",
       "      <td>2.3289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.689741</td>\n",
       "      <td>7.207860</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>2.552838</td>\n",
       "      <td>1.188000e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD65fgYti96iSSzSPaNazV9Bs29m7JbNomGjG4Cp5WFS</td>\n",
       "      <td>11.129202</td>\n",
       "      <td>13.842510</td>\n",
       "      <td>13.857868</td>\n",
       "      <td>3.438904</td>\n",
       "      <td>2.429156</td>\n",
       "      <td>7.996654</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.575033</td>\n",
       "      <td>3.1848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.693347</td>\n",
       "      <td>6.317165</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.392913</td>\n",
       "      <td>2.088910e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4zVhwuUsFbcaty7wJhNEZ7VEwPHXQ5d2heXPxM5yWhL</td>\n",
       "      <td>11.224163</td>\n",
       "      <td>13.664448</td>\n",
       "      <td>13.662299</td>\n",
       "      <td>3.158480</td>\n",
       "      <td>2.394736</td>\n",
       "      <td>7.167230</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.893753</td>\n",
       "      <td>2.1342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.712116</td>\n",
       "      <td>7.147559</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>-0.897393</td>\n",
       "      <td>-8.850000e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060967</th>\n",
       "      <td>8R4bAxT8sPTo9H3du5o44ZjEnZbGaokdEhpXpu33nhWe</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.887274</td>\n",
       "      <td>4.988889e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060968</th>\n",
       "      <td>6iFf3f46xz8AxUwWobQEdXBkEaf9wMoae8WpBF3fLQxV</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.900121</td>\n",
       "      <td>4.988889e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060969</th>\n",
       "      <td>6Uh4ADbZk9x4NPzCTQHAAGeLhD2rZQvhFshWjmLigv3j</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.804689</td>\n",
       "      <td>4.988889e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060970</th>\n",
       "      <td>7UD1qAyK2YE9N5c9vZn8Zg3Pxke6njfrgdjBjTqMrH2g</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>4.988889e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060971</th>\n",
       "      <td>6R1aJyyNaTS2CC8ifSCQLzmFNJ5bYYk9Ui8NPHWydpwc</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.400229</td>\n",
       "      <td>4.988889e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10060972 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               swapper  total_trades_count  \\\n",
       "0          arsc4jbDnzaqcCLByyGo7fg7S2SmcFsWUzQuDtLZh2y           11.929218   \n",
       "1         HV1KXxWFaSeriyFvXyx48FqG9BoFbfinB8njCJonqP7K           14.062294   \n",
       "2         8MqRTAQnjhDYH7TWS1b1DjFog4CLZfySWE5cZeotG2VW           11.565319   \n",
       "3         AD65fgYti96iSSzSPaNazV9Bs29m7JbNomGjG4Cp5WFS           11.129202   \n",
       "4         D4zVhwuUsFbcaty7wJhNEZ7VEwPHXQ5d2heXPxM5yWhL           11.224163   \n",
       "...                                                ...                 ...   \n",
       "10060967  8R4bAxT8sPTo9H3du5o44ZjEnZbGaokdEhpXpu33nhWe            2.302585   \n",
       "10060968  6iFf3f46xz8AxUwWobQEdXBkEaf9wMoae8WpBF3fLQxV            2.302585   \n",
       "10060969  6Uh4ADbZk9x4NPzCTQHAAGeLhD2rZQvhFshWjmLigv3j            1.945910   \n",
       "10060970  7UD1qAyK2YE9N5c9vZn8Zg3Pxke6njfrgdjBjTqMrH2g            2.079442   \n",
       "10060971  6R1aJyyNaTS2CC8ifSCQLzmFNJ5bYYk9Ui8NPHWydpwc            0.693147   \n",
       "\n",
       "          total_sol_spent  total_sol_received  avg_sol_trade_size  \\\n",
       "0               14.967902           14.981749            3.755503   \n",
       "1               14.261920           10.102181            0.833605   \n",
       "2               14.015515           14.028511            3.188866   \n",
       "3               13.842510           13.857868            3.438904   \n",
       "4               13.664448           13.662299            3.158480   \n",
       "...                   ...                 ...                 ...   \n",
       "10060967         0.000000            0.887258                 NaN   \n",
       "10060968         0.000000            0.900102                 NaN   \n",
       "10060969         0.000000            0.804676                 NaN   \n",
       "10060970         0.000000            0.754282                 NaN   \n",
       "10060971         0.000000            2.400225                 NaN   \n",
       "\n",
       "          median_sol_trade_size  max_single_sol_trade  min_sol_trade_size  \\\n",
       "0                      2.798872              7.996654              0.0001   \n",
       "1                      0.162034              7.754392              0.0000   \n",
       "2                      2.346966              7.613638              0.0001   \n",
       "3                      2.429156              7.996654              0.0000   \n",
       "4                      2.394736              7.167230              0.0000   \n",
       "...                         ...                   ...                 ...   \n",
       "10060967                    NaN              0.000000                 NaN   \n",
       "10060968                    NaN              0.000000                 NaN   \n",
       "10060969                    NaN              0.000000                 NaN   \n",
       "10060970                    NaN              0.000000                 NaN   \n",
       "10060971                    NaN              0.000000                 NaN   \n",
       "\n",
       "          sol_trade_size_std_dev  trade_size_coefficient_variation  ...  \\\n",
       "0                       4.686332                            2.5734  ...   \n",
       "1                       2.147451                            5.8106  ...   \n",
       "2                       4.010474                            2.3289  ...   \n",
       "3                       4.575033                            3.1848  ...   \n",
       "4                       3.893753                            2.1342  ...   \n",
       "...                          ...                               ...  ...   \n",
       "10060967                     NaN                               NaN  ...   \n",
       "10060968                     NaN                               NaN  ...   \n",
       "10060969                     NaN                               NaN  ...   \n",
       "10060970                     NaN                               NaN  ...   \n",
       "10060971                     NaN                               NaN  ...   \n",
       "\n",
       "          sol_to_token_percentage  token_to_sol_percentage  \\\n",
       "0                          0.5000                   0.5000   \n",
       "1                          0.9380                   0.0081   \n",
       "2                          0.4983                   0.5017   \n",
       "3                          0.5001                   0.4999   \n",
       "4                          0.5093                   0.4905   \n",
       "...                           ...                      ...   \n",
       "10060967                   0.0000                   1.0000   \n",
       "10060968                   0.0000                   1.0000   \n",
       "10060969                   0.0000                   1.0000   \n",
       "10060970                   0.0000                   1.0000   \n",
       "10060971                   0.0000                   1.0000   \n",
       "\n",
       "          token_to_token_percentage  buy_sell_ratio  total_positions  \\\n",
       "0                            0.0000        0.693147         5.579730   \n",
       "1                            0.0538        4.758732         8.108322   \n",
       "2                            0.0000        0.689741         7.207860   \n",
       "3                            0.0000        0.693347         6.317165   \n",
       "4                            0.0002        0.712116         7.147559   \n",
       "...                             ...             ...              ...   \n",
       "10060967                     0.0000        0.000000         0.693147   \n",
       "10060968                     0.0000        0.000000         0.693147   \n",
       "10060969                     0.0000        0.000000         0.693147   \n",
       "10060970                     0.0000        0.000000         0.693147   \n",
       "10060971                     0.0000        0.000000         0.693147   \n",
       "\n",
       "          win_rate  avg_pnl_per_position       avg_roi  has_buy_history  \\\n",
       "0           1.0000              5.125131  1.520000e-01                1   \n",
       "1           0.0018             -6.140320 -9.922000e-01                1   \n",
       "2           0.9978              2.552838  1.188000e-01                1   \n",
       "3           0.9964              3.392913  2.088910e+01                1   \n",
       "4           0.4976             -0.897393 -8.850000e-02                1   \n",
       "...            ...                   ...           ...              ...   \n",
       "10060967    1.0000              0.887274  4.988889e+11                0   \n",
       "10060968    1.0000              0.900121  4.988889e+11                0   \n",
       "10060969    1.0000              0.804689  4.988889e+11                0   \n",
       "10060970    1.0000              0.754289  4.988889e+11                0   \n",
       "10060971    1.0000              2.400229  4.988889e+11                0   \n",
       "\n",
       "          is_multi_trader  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       1  \n",
       "...                   ...  \n",
       "10060967                1  \n",
       "10060968                1  \n",
       "10060969                1  \n",
       "10060970                1  \n",
       "10060971                0  \n",
       "\n",
       "[10060972 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARING FINAL CLUSTERING DATASET ===\n",
      "Clustering dataset shape: (10060972, 36)\n",
      "Remaining missing values: 0\n",
      "Final feature set: 35 numeric features\n",
      "Features: ['total_trades_count', 'total_sol_spent', 'total_sol_received', 'avg_sol_trade_size', 'median_sol_trade_size', 'max_single_sol_trade', 'min_sol_trade_size', 'sol_trade_size_std_dev', 'trade_size_coefficient_variation', 'net_sol_pnl', 'unique_coins_traded', 'avg_trades_per_coin', 'trade_concentration_ratio', 'trading_span_days', 'trades_per_day', 'avg_hours_between_trades', 'active_hours', 'active_days', 'trades_per_active_hour', 'round_number_preference', 'sol_to_token_trades', 'token_to_sol_trades', 'token_to_token_trades', 'unique_from_tokens_non_sol', 'unique_to_tokens_non_sol', 'sol_to_token_percentage', 'token_to_sol_percentage', 'token_to_token_percentage', 'buy_sell_ratio', 'total_positions', 'win_rate', 'avg_pnl_per_position', 'avg_roi', 'has_buy_history', 'is_multi_trader']\n",
      "\n",
      "Saved cluster_features.pkl (10,060,972 rows × 35 cols)\n",
      "Saved trader_ids.pkl (10,060,972 trader IDs)\n",
      "Estimated memory usage: 2.29 GB\n"
     ]
    }
   ],
   "source": [
    "# Save the prepared features to pickle for memory-efficient loading\n",
    "# Clean up df_prep for clustering - remove ID column and handle remaining missing values\n",
    "print(\"=== PREPARING FINAL CLUSTERING DATASET ===\")\n",
    "\n",
    "  # Handle remaining missing values by filling with 0 (these are from insider traders with no buy history)\n",
    "cluster_features = df_prep.fillna(0)\n",
    "\n",
    "print(f\"Clustering dataset shape: {cluster_features.shape}\")\n",
    "print(f\"Remaining missing values: {cluster_features.isnull().sum().sum()}\")\n",
    "\n",
    "  # Select only numeric features for clustering (all should be numeric at this point)\n",
    "numeric_cols = cluster_features.select_dtypes(include=[np.number]).columns\n",
    "cluster_features_final = cluster_features[numeric_cols]\n",
    "\n",
    "print(f\"Final feature set: {len(cluster_features_final.columns)} numeric features\")\n",
    "print(f\"Features: {list(cluster_features_final.columns)}\")\n",
    "\n",
    "  # Save the processed features to pickle for memory-efficient loading\n",
    "import pickle\n",
    "\n",
    "path = '/Volumes/Extreme SSD/trading_data/solana/trader_features/'\n",
    "\n",
    "  # save merged_features\n",
    "with open(path + 'merged_features.pkl', 'wb') as f:\n",
    "      pickle.dump(merged_features, f)\n",
    "\n",
    "  # Save cluster-ready features \n",
    "with open(path + 'cluster_features.pkl', 'wb') as f:\n",
    "      pickle.dump(cluster_features_final, f)\n",
    "\n",
    "  # Save trader IDs separately\n",
    "trader_ids = df_prep['swapper'].copy()\n",
    "with open(path + 'trader_ids.pkl', 'wb') as f:\n",
    "      pickle.dump(trader_ids, f)\n",
    "\n",
    "print(f\"\\nSaved cluster_features.pkl ({cluster_features_final.shape[0]:,} rows × {cluster_features_final.shape[1]} cols)\")\n",
    "print(f\"Saved trader_ids.pkl ({len(trader_ids):,} trader IDs)\")\n",
    "\n",
    "  # Memory usage estimation\n",
    "memory_gb = (cluster_features_final.memory_usage(deep=True).sum()) / (1024**3)\n",
    "print(f\"Estimated memory usage: {memory_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/Extreme SSD/trading_data/solana/trader_features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOADING PREPARED DATA ===\n",
      "Loaded cluster features: (10060972, 35)\n",
      "Loaded trader IDs: 10,060,972\n",
      "\n",
      "=== APPLYING STANDARDSCALER ===\n",
      "Scaled features shape: (10060972, 35)\n",
      "Feature means after scaling: [0.00000000e+00 9.25678527e-17 9.25678527e-17 0.00000000e+00\n",
      " 4.62839264e-17]\n",
      "Feature std after scaling: [1. 1. 1. 1. 1.]\n",
      "Scaled data memory usage: 2.62 GB\n"
     ]
    }
   ],
   "source": [
    "# Load the prepared features from pickle files\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"=== LOADING PREPARED DATA ===\")\n",
    "\n",
    "# Load cluster features\n",
    "with open(path + 'cluster_features.pkl', 'rb') as f:\n",
    "    cluster_features = pickle.load(f)\n",
    "\n",
    "# Load trader IDs\n",
    "with open(path + 'trader_ids.pkl', 'rb') as f:\n",
    "    trader_ids = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded cluster features: {cluster_features.shape}\")\n",
    "print(f\"Loaded trader IDs: {len(trader_ids):,}\")\n",
    "\n",
    "# Apply StandardScaler\n",
    "print(\"\\n=== APPLYING STANDARDSCALER ===\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(cluster_features)\n",
    "\n",
    "print(f\"Scaled features shape: {X_scaled.shape}\")\n",
    "print(f\"Feature means after scaling: {X_scaled.mean(axis=0)[:5]}\")  # Show first 5 means (should be ~0)\n",
    "print(f\"Feature std after scaling: {X_scaled.std(axis=0)[:5]}\")    # Show first 5 stds (should be ~1)\n",
    "\n",
    "# Memory usage check\n",
    "memory_gb = (X_scaled.nbytes) / (1024**3)\n",
    "print(f\"Scaled data memory usage: {memory_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGNOSING NUMERICAL ISSUES ===\n",
      "1. Checking for problematic values in cluster_features:\n",
      "   Shape: (10060972, 35)\n",
      "   ✓ No infinite values found\n",
      "   ✓ No NaN values found\n",
      "\n",
      "2. Checking for extremely large values:\n",
      "   ✓ No extremely large values found\n",
      "\n",
      "3. Checking for zero/near-zero variance columns:\n",
      "   ✓ No zero variance columns found\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSE NUMERICAL ISSUES\n",
    "print(\"=== DIAGNOSING NUMERICAL ISSUES ===\")\n",
    "\n",
    "# Check for problematic values in the original features\n",
    "print(\"1. Checking for problematic values in cluster_features:\")\n",
    "print(f\"   Shape: {cluster_features.shape}\")\n",
    "\n",
    "# Check for infinite values\n",
    "inf_cols = []\n",
    "for col in cluster_features.columns:\n",
    "    inf_count = np.isinf(cluster_features[col]).sum()\n",
    "    if inf_count > 0:\n",
    "        inf_cols.append((col, inf_count))\n",
    "\n",
    "if inf_cols:\n",
    "    print(f\"\\n   Infinite values found in {len(inf_cols)} columns:\")\n",
    "    for col, count in inf_cols:\n",
    "        print(f\"     {col}: {count:,} infinite values\")\n",
    "else:\n",
    "    print(\"   ✓ No infinite values found\")\n",
    "\n",
    "# Check for NaN values\n",
    "nan_cols = []\n",
    "for col in cluster_features.columns:\n",
    "    nan_count = cluster_features[col].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        nan_cols.append((col, nan_count))\n",
    "\n",
    "if nan_cols:\n",
    "    print(f\"\\n   NaN values found in {len(nan_cols)} columns:\")\n",
    "    for col, count in nan_cols:\n",
    "        print(f\"     {col}: {count:,} NaN values\")\n",
    "else:\n",
    "    print(\"   ✓ No NaN values found\")\n",
    "\n",
    "# Check for extremely large values\n",
    "print(\"\\n2. Checking for extremely large values:\")\n",
    "large_value_cols = []\n",
    "for col in cluster_features.columns:\n",
    "    max_val = cluster_features[col].max()\n",
    "    if max_val > 1e10:  # Values larger than 10 billion\n",
    "        large_value_cols.append((col, max_val))\n",
    "\n",
    "if large_value_cols:\n",
    "    print(f\"   Large values found in {len(large_value_cols)} columns:\")\n",
    "    for col, max_val in large_value_cols:\n",
    "        print(f\"     {col}: max = {max_val:.2e}\")\n",
    "else:\n",
    "    print(\"   ✓ No extremely large values found\")\n",
    "\n",
    "# Check for zero variance columns\n",
    "print(\"\\n3. Checking for zero/near-zero variance columns:\")\n",
    "zero_var_cols = []\n",
    "for col in cluster_features.columns:\n",
    "    var = cluster_features[col].var()\n",
    "    if var < 1e-10:  # Essentially zero variance\n",
    "        zero_var_cols.append((col, var))\n",
    "\n",
    "if zero_var_cols:\n",
    "    print(f\"   Zero variance columns found: {len(zero_var_cols)}\")\n",
    "    for col, var in zero_var_cols:\n",
    "        print(f\"     {col}: variance = {var:.2e}\")\n",
    "else:\n",
    "    print(\"   ✓ No zero variance columns found\")\n",
    "\n",
    "# Sample statistics for problematic columns\n",
    "if large_value_cols:\n",
    "    print(f\"\\n4. Detailed statistics for problematic columns:\")\n",
    "    for col, _ in large_value_cols[:3]:  # Show first 3 problematic columns\n",
    "        col_data = cluster_features[col]\n",
    "        print(f\"\\n   {col}:\")\n",
    "        print(f\"     Min: {col_data.min():.2e}\")\n",
    "        print(f\"     Max: {col_data.max():.2e}\")\n",
    "        print(f\"     Mean: {col_data.mean():.2e}\")\n",
    "        print(f\"     Std: {col_data.std():.2e}\")\n",
    "        print(f\"     >1e9 values: {(col_data > 1e9).sum():,}\")\n",
    "        print(f\"     >1e12 values: {(col_data > 1e12).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One time run for normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SMART FIX FOR INSIDER ROI PROBLEM ===\n",
      "1. Fixing the avg_roi insider trader issue...\n",
      "   Regular trader 99th percentile ROI: 3.56\n",
      "   Using insider marker value: 1000.00\n",
      "   Original insider ROI value: 4.99e+11\n",
      "   Fixed 944,706 insider trader ROI values\n",
      "\n",
      "2. Capping extreme regular trader ROI values...\n",
      "   Capping 112,801 extreme regular trader ROI values\n",
      "   Bounds: [-3.98, 2.97]\n",
      "\n",
      "3. Verifying the fix...\n",
      "   New avg_roi statistics:\n",
      "     Min: -1.00\n",
      "     Max: 1000.00\n",
      "     Mean: 93.53\n",
      "     Std: 291.81\n",
      "     Maximum absolute value: 1.00e+03\n",
      "     ✓ Values are now in a reasonable range for clustering\n",
      "\n",
      "4. Applying robust preprocessing to all features...\n",
      "   avg_roi: capped 944,706 outliers to [-4.09e+00, 3.12e+00]\n",
      "\n",
      "Fixed dataset shape: (10060972, 35)\n",
      "✓ Updated cluster_features with numerically stable data\n"
     ]
    }
   ],
   "source": [
    "# No need to run this cell because we already have a fixed version of cluster_features\n",
    "# SMART FIX FOR INSIDER ROI PROBLEM\n",
    "print(\"=== SMART FIX FOR INSIDER ROI PROBLEM ===\")\n",
    "\n",
    "# Create a properly cleaned version of cluster_features\n",
    "cluster_features_fixed = cluster_features.copy()\n",
    "\n",
    "print(\"1. Fixing the avg_roi insider trader issue...\")\n",
    "\n",
    "# Strategy: Replace the unrealistic 498+ billion ROI with a reasonable marker value\n",
    "# that still preserves the insider trader signal but doesn't break clustering\n",
    "\n",
    "# For insider traders (has_buy_history=0), replace extreme ROI with a reasonable marker\n",
    "insider_mask = cluster_features_fixed['has_buy_history'] == 0\n",
    "regular_mask = cluster_features_fixed['has_buy_history'] == 1\n",
    "\n",
    "# Calculate a reasonable marker value based on regular trader ROI distribution\n",
    "regular_roi_values = cluster_features_fixed.loc[regular_mask, 'avg_roi']\n",
    "p99_regular_roi = regular_roi_values.quantile(0.99)\n",
    "p95_regular_roi = regular_roi_values.quantile(0.95)\n",
    "\n",
    "# Use 10x the 99th percentile as the insider marker (clearly separates but reasonable)\n",
    "insider_marker_value = max(10 * p99_regular_roi, 1000)  # At least 1000x ROI\n",
    "\n",
    "print(f\"   Regular trader 99th percentile ROI: {p99_regular_roi:.2f}\")\n",
    "print(f\"   Using insider marker value: {insider_marker_value:.2f}\")\n",
    "print(f\"   Original insider ROI value: {cluster_features_fixed.loc[insider_mask, 'avg_roi'].iloc[0]:.2e}\")\n",
    "\n",
    "# Replace insider ROI values\n",
    "cluster_features_fixed.loc[insider_mask, 'avg_roi'] = insider_marker_value\n",
    "\n",
    "print(f\"   Fixed {insider_mask.sum():,} insider trader ROI values\")\n",
    "\n",
    "# 2. Cap extreme regular trader ROI values using robust method\n",
    "print(f\"\\n2. Capping extreme regular trader ROI values...\")\n",
    "\n",
    "# For regular traders, cap extreme outliers using IQR method\n",
    "regular_roi_data = cluster_features_fixed.loc[regular_mask, 'avg_roi']\n",
    "Q1 = regular_roi_data.quantile(0.25)\n",
    "Q3 = regular_roi_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# More conservative bounds for financial data\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "# Apply capping only to regular traders\n",
    "extreme_regular_mask = regular_mask & (\n",
    "    (cluster_features_fixed['avg_roi'] < lower_bound) | \n",
    "    (cluster_features_fixed['avg_roi'] > upper_bound)\n",
    ")\n",
    "\n",
    "if extreme_regular_mask.any():\n",
    "    print(f\"   Capping {extreme_regular_mask.sum():,} extreme regular trader ROI values\")\n",
    "    print(f\"   Bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    cluster_features_fixed.loc[extreme_regular_mask, 'avg_roi'] = np.clip(\n",
    "        cluster_features_fixed.loc[extreme_regular_mask, 'avg_roi'],\n",
    "        lower_bound,\n",
    "        upper_bound\n",
    "    )\n",
    "\n",
    "# 3. Verify the fix\n",
    "print(f\"\\n3. Verifying the fix...\")\n",
    "fixed_roi = cluster_features_fixed['avg_roi']\n",
    "print(f\"   New avg_roi statistics:\")\n",
    "print(f\"     Min: {fixed_roi.min():.2f}\")\n",
    "print(f\"     Max: {fixed_roi.max():.2f}\")\n",
    "print(f\"     Mean: {fixed_roi.mean():.2f}\")\n",
    "print(f\"     Std: {fixed_roi.std():.2f}\")\n",
    "\n",
    "# Check for numerical stability\n",
    "max_abs_value = np.abs(fixed_roi).max()\n",
    "print(f\"     Maximum absolute value: {max_abs_value:.2e}\")\n",
    "\n",
    "if max_abs_value < 1e6:\n",
    "    print(\"     ✓ Values are now in a reasonable range for clustering\")\n",
    "elif max_abs_value < 1e9:\n",
    "    print(\"     ⚠️  Values are better but still large - monitor clustering\")\n",
    "else:\n",
    "    print(\"     ❌ Values are still too large - need further preprocessing\")\n",
    "\n",
    "# 4. Apply the fix to all problematic features\n",
    "print(f\"\\n4. Applying robust preprocessing to all features...\")\n",
    "\n",
    "for col in cluster_features_fixed.columns:\n",
    "    if col in ['has_buy_history', 'is_multi_trader']:  # Skip binary indicators\n",
    "        continue\n",
    "        \n",
    "    col_data = cluster_features_fixed[col]\n",
    "    \n",
    "    # Skip if already reasonable\n",
    "    if np.abs(col_data).max() < 1e3:\n",
    "        continue\n",
    "    \n",
    "    # Apply robust capping using IQR method\n",
    "    Q1 = col_data.quantile(0.25)\n",
    "    Q3 = col_data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    if IQR > 0:  # Avoid division by zero\n",
    "        lower_bound = Q1 - 3 * IQR\n",
    "        upper_bound = Q3 + 3 * IQR\n",
    "        \n",
    "        outlier_count = ((col_data < lower_bound) | (col_data > upper_bound)).sum()\n",
    "        if outlier_count > 0:\n",
    "            cluster_features_fixed[col] = col_data.clip(lower_bound, upper_bound)\n",
    "            print(f\"   {col}: capped {outlier_count:,} outliers to [{lower_bound:.2e}, {upper_bound:.2e}]\")\n",
    "\n",
    "print(f\"\\nFixed dataset shape: {cluster_features_fixed.shape}\")\n",
    "\n",
    "# Update the cluster_features for subsequent use\n",
    "cluster_features = cluster_features_fixed\n",
    "print(f\"✓ Updated cluster_features with numerically stable data\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "  # Save cluster-ready features \n",
    "with open(path + 'cluster_features.pkl', 'wb') as f:\n",
    "      pickle.dump(cluster_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
