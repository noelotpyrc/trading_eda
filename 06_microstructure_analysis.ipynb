{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Microstructure Mean Reversion Analysis\n",
        "\n",
        "This notebook analyzes high-frequency mean reversion patterns in NVDA data, focusing on:\n",
        "- Mean reversion analysis across different timeframes (1-min, 5-min, 15-min)\n",
        "- Bid-ask bounce patterns using OHLC spread proxies\n",
        "- Overreaction/correction cycles after large price moves\n",
        "- Half-life of price dislocations and optimal entry/exit timing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded data shape: (865782, 13)\n",
            "Date range: 2021-01-04 00:00:00 to 2025-05-30 00:00:00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Load the cleaned data\n",
        "all_data = pd.read_csv('combined_nvda_ohlc_clean.csv')\n",
        "all_data['date'] = pd.to_datetime(all_data['date'])\n",
        "all_data['datetime'] = pd.to_datetime(all_data['datetime'])\n",
        "\n",
        "# Sort by datetime\n",
        "all_data_sorted = all_data.sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "print(f\"Loaded data shape: {all_data.shape}\")\n",
        "print(f\"Date range: {all_data['date'].min()} to {all_data['date'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-minute data: 865782 observations\n",
            "5-minute data: 199944 observations\n",
            "15-minute data: 69363 observations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/my/18kmg51d1lz3l9rnds2gkf1r0000gn/T/ipykernel_6290/2898220697.py:8: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = data_copy.resample(freq).agg({\n",
            "/var/folders/my/18kmg51d1lz3l9rnds2gkf1r0000gn/T/ipykernel_6290/2898220697.py:8: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = data_copy.resample(freq).agg({\n"
          ]
        }
      ],
      "source": [
        "# Create different timeframe datasets\n",
        "def create_timeframe_data(data, freq):\n",
        "    \"\"\"Resample data to different frequencies\"\"\"\n",
        "    data_copy = data.copy()\n",
        "    data_copy.set_index('datetime', inplace=True)\n",
        "    \n",
        "    # Resample OHLC data\n",
        "    resampled = data_copy.resample(freq).agg({\n",
        "        'open': 'first',\n",
        "        'high': 'max',\n",
        "        'low': 'min',\n",
        "        'close': 'last',\n",
        "        'volume': 'sum',\n",
        "        'transactions': 'sum'\n",
        "    }).dropna()\n",
        "    \n",
        "    # Calculate returns\n",
        "    resampled['returns'] = resampled['close'].pct_change()\n",
        "    \n",
        "    # Calculate HL spread\n",
        "    resampled['hl_spread'] = resampled['high'] - resampled['low']\n",
        "    resampled['hl_spread_pct'] = (resampled['hl_spread'] / resampled['close']) * 100\n",
        "    \n",
        "    return resampled\n",
        "\n",
        "# Create datasets for different timeframes\n",
        "data_1min = all_data_sorted.copy()\n",
        "data_1min['returns'] = data_1min['close'].pct_change()\n",
        "data_1min['hl_spread'] = data_1min['high'] - data_1min['low']\n",
        "data_1min['hl_spread_pct'] = (data_1min['hl_spread'] / data_1min['close']) * 100\n",
        "\n",
        "data_5min = create_timeframe_data(all_data_sorted, '5T')\n",
        "data_15min = create_timeframe_data(all_data_sorted, '15T')\n",
        "\n",
        "print(f\"1-minute data: {len(data_1min)} observations\")\n",
        "print(f\"5-minute data: {len(data_5min)} observations\") \n",
        "print(f\"15-minute data: {len(data_15min)} observations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Reversion Analysis\n",
        "\n",
        "Analyze mean reversion characteristics across different timeframes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Mean Reversion Analysis: 1-Minute ===\n",
            "Lag-1 Autocorrelation: -0.0395\n",
            "Lag-2 Autocorrelation: -0.0132\n",
            "Lag-3 Autocorrelation: -0.0038\n",
            "Lag-5 Autocorrelation: -0.0044\n",
            "Lag-10 Autocorrelation: 0.0053\n",
            "AR(1) coefficient (β): -0.0395\n",
            "Half-life: 0.21 periods\n",
            "Half-life in minutes: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/noel/projects/trading_eda/.venv/lib/python3.13/site-packages/statsmodels/tools/tools.py:274: RuntimeWarning: divide by zero encountered in dot\n",
            "  res = np.dot(np.transpose(vt), np.multiply(s[:, np.newaxis],\n",
            "/Users/noel/projects/trading_eda/.venv/lib/python3.13/site-packages/statsmodels/tools/tools.py:274: RuntimeWarning: overflow encountered in dot\n",
            "  res = np.dot(np.transpose(vt), np.multiply(s[:, np.newaxis],\n",
            "/Users/noel/projects/trading_eda/.venv/lib/python3.13/site-packages/statsmodels/tools/tools.py:274: RuntimeWarning: invalid value encountered in dot\n",
            "  res = np.dot(np.transpose(vt), np.multiply(s[:, np.newaxis],\n",
            "/Users/noel/projects/trading_eda/.venv/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:341: RuntimeWarning: divide by zero encountered in dot\n",
            "  beta = np.dot(self.pinv_wexog, self.wendog)\n",
            "/Users/noel/projects/trading_eda/.venv/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:341: RuntimeWarning: overflow encountered in dot\n",
            "  beta = np.dot(self.pinv_wexog, self.wendog)\n",
            "/Users/noel/projects/trading_eda/.venv/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:341: RuntimeWarning: invalid value encountered in dot\n",
            "  beta = np.dot(self.pinv_wexog, self.wendog)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADF test failed\n"
          ]
        }
      ],
      "source": [
        "def analyze_mean_reversion(data, name):\n",
        "    \"\"\"\n",
        "    Comprehensive mean reversion analysis\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Mean Reversion Analysis: {name} ===\")\n",
        "    \n",
        "    returns = data['returns'].dropna()\n",
        "    \n",
        "    if len(returns) < 50:\n",
        "        print(f\"Insufficient data for {name}\")\n",
        "        return None\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    # 1. Autocorrelation analysis\n",
        "    lags = [1, 2, 3, 5, 10]\n",
        "    autocorrs = []\n",
        "    \n",
        "    for lag in lags:\n",
        "        autocorr = returns.autocorr(lag=lag)\n",
        "        autocorrs.append(autocorr)\n",
        "        print(f\"Lag-{lag} Autocorrelation: {autocorr:.4f}\")\n",
        "    \n",
        "    results['autocorrelations'] = dict(zip(lags, autocorrs))\n",
        "    \n",
        "    # 2. Half-life calculation using AR(1) model\n",
        "    # Create lagged returns\n",
        "    lagged_returns = returns.shift(1).dropna()\n",
        "    current_returns = returns[1:].values\n",
        "    \n",
        "    if len(current_returns) > 20:\n",
        "        # Fit AR(1): r_t = α + β*r_{t-1} + ε_t\n",
        "        X = lagged_returns.values.reshape(-1, 1)\n",
        "        y = current_returns\n",
        "        \n",
        "        model = LinearRegression()\n",
        "        model.fit(X, y)\n",
        "        \n",
        "        beta = model.coef_[0]\n",
        "        alpha = model.intercept_\n",
        "        \n",
        "        # Half-life calculation: HL = -ln(2)/ln(|β|) for |β| < 1\n",
        "        if abs(beta) < 1 and beta != 0:\n",
        "            half_life = -np.log(2) / np.log(abs(beta))\n",
        "            print(f\"AR(1) coefficient (β): {beta:.4f}\")\n",
        "            print(f\"Half-life: {half_life:.2f} periods\")\n",
        "            \n",
        "            # Convert to time units\n",
        "            if 'min' in name.lower():\n",
        "                if '1' in name:\n",
        "                    hl_minutes = half_life * 1\n",
        "                elif '5' in name:\n",
        "                    hl_minutes = half_life * 5\n",
        "                elif '15' in name:\n",
        "                    hl_minutes = half_life * 15\n",
        "                print(f\"Half-life in minutes: {hl_minutes:.1f}\")\n",
        "        else:\n",
        "            half_life = np.inf\n",
        "            print(\"No mean reversion detected (β >= 1)\")\n",
        "        \n",
        "        results['ar1_beta'] = beta\n",
        "        results['ar1_alpha'] = alpha\n",
        "        results['half_life'] = half_life\n",
        "    \n",
        "    # 3. ADF test for stationarity\n",
        "    try:\n",
        "        adf_result = adfuller(returns.dropna())\n",
        "        results['adf_statistic'] = adf_result[0]\n",
        "        results['adf_pvalue'] = adf_result[1]\n",
        "        print(f\"ADF Test - Statistic: {adf_result[0]:.4f}, p-value: {adf_result[1]:.4f}\")\n",
        "        \n",
        "        if adf_result[1] < 0.05:\n",
        "            print(\"Series is stationary (mean-reverting)\")\n",
        "        else:\n",
        "            print(\"Series is non-stationary\")\n",
        "    except:\n",
        "        print(\"ADF test failed\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze mean reversion for different timeframes\n",
        "mr_results = {}\n",
        "mr_results['1min'] = analyze_mean_reversion(data_1min, \"1-Minute\")\n",
        "#mr_results['5min'] = analyze_mean_reversion(data_5min, \"5-Minute\") \n",
        "#mr_results['15min'] = analyze_mean_reversion(data_15min, \"15-Minute\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bid-Ask Bounce Analysis\n",
        "\n",
        "Analyze bid-ask bounce patterns using OHLC spread as proxy for market microstructure effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Bid-Ask Bounce Analysis: 1-Minute ===\n",
            "Insufficient data for 1-Minute\n",
            "\n",
            "=== Bid-Ask Bounce Analysis: 5-Minute ===\n",
            "Mean HL Spread: $0.1526\n",
            "Median HL Spread: $0.0680\n",
            "Std HL Spread: $0.2735\n",
            "Mean HL Spread %: 0.2706%\n",
            "Spread-Volume Correlation: 0.5800\n",
            "75th percentile spread: 0.3501%\n",
            "25th percentile spread: 0.0806%\n",
            "Bounce patterns detected: 1782/49986 (3.56%)\n",
            "\n",
            "=== Bid-Ask Bounce Analysis: 15-Minute ===\n",
            "Mean HL Spread: $0.2678\n",
            "Median HL Spread: $0.1200\n",
            "Std HL Spread: $0.4523\n",
            "Mean HL Spread %: 0.4816%\n",
            "Spread-Volume Correlation: 0.5887\n",
            "75th percentile spread: 0.6203%\n",
            "25th percentile spread: 0.1589%\n",
            "Bounce patterns detected: 1000/17341 (5.77%)\n"
          ]
        }
      ],
      "source": [
        "def analyze_bid_ask_bounce(data, name):\n",
        "    \"\"\"\n",
        "    Analyze bid-ask bounce patterns using OHLC spread as proxy\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Bid-Ask Bounce Analysis: {name} ===\")\n",
        "    \n",
        "    clean_data = data.dropna()\n",
        "    \n",
        "    if len(clean_data) < 50:\n",
        "        print(f\"Insufficient data for {name}\")\n",
        "        return None\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    # 1. Calculate spread statistics\n",
        "    hl_spread = clean_data['hl_spread']\n",
        "    hl_spread_pct = clean_data['hl_spread_pct']\n",
        "    \n",
        "    print(f\"Mean HL Spread: ${hl_spread.mean():.4f}\")\n",
        "    print(f\"Median HL Spread: ${hl_spread.median():.4f}\")\n",
        "    print(f\"Std HL Spread: ${hl_spread.std():.4f}\")\n",
        "    print(f\"Mean HL Spread %: {hl_spread_pct.mean():.4f}%\")\n",
        "    \n",
        "    results['spread_stats'] = {\n",
        "        'mean': hl_spread.mean(),\n",
        "        'median': hl_spread.median(),\n",
        "        'std': hl_spread.std(),\n",
        "        'mean_pct': hl_spread_pct.mean()\n",
        "    }\n",
        "    \n",
        "    # 2. Analyze relationship between spread and volume\n",
        "    if 'volume' in clean_data.columns:\n",
        "        correlation = clean_data['hl_spread_pct'].corr(clean_data['volume'])\n",
        "        print(f\"Spread-Volume Correlation: {correlation:.4f}\")\n",
        "        results['spread_volume_corr'] = correlation\n",
        "    \n",
        "    # 3. Detect bounce patterns: high spread followed by low spread\n",
        "    # Define high spread as > 75th percentile, low spread as < 25th percentile\n",
        "    spread_75th = hl_spread_pct.quantile(0.75)\n",
        "    spread_25th = hl_spread_pct.quantile(0.25)\n",
        "    \n",
        "    print(f\"75th percentile spread: {spread_75th:.4f}%\")\n",
        "    print(f\"25th percentile spread: {spread_25th:.4f}%\")\n",
        "    \n",
        "    # Find bounce patterns (high spread followed by low spread within next few periods)\n",
        "    high_spread_mask = hl_spread_pct > spread_75th\n",
        "    bounce_count = 0\n",
        "    total_high_spread = high_spread_mask.sum()\n",
        "    \n",
        "    for i in range(len(clean_data) - 3):\n",
        "        if high_spread_mask.iloc[i]:\n",
        "            # Check if any of the next 3 periods have low spread\n",
        "            next_3_periods = hl_spread_pct.iloc[i+1:i+4]\n",
        "            if (next_3_periods < spread_25th).any():\n",
        "                bounce_count += 1\n",
        "    \n",
        "    bounce_rate = bounce_count / total_high_spread if total_high_spread > 0 else 0\n",
        "    print(f\"Bounce patterns detected: {bounce_count}/{total_high_spread} ({bounce_rate:.2%})\")\n",
        "    \n",
        "    results['bounce_patterns'] = {\n",
        "        'bounce_count': bounce_count,\n",
        "        'total_high_spread': total_high_spread,\n",
        "        'bounce_rate': bounce_rate\n",
        "    }\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze bid-ask bounce for different timeframes\n",
        "bounce_results = {}\n",
        "bounce_results['1min'] = analyze_bid_ask_bounce(data_1min, \"1-Minute\")\n",
        "bounce_results['5min'] = analyze_bid_ask_bounce(data_5min, \"5-Minute\")\n",
        "bounce_results['15min'] = analyze_bid_ask_bounce(data_15min, \"15-Minute\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
